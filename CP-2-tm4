import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import scipy.stats as stats
from scipy.optimize import minimize
import warnings
import time

warnings.filterwarnings('ignore')

print("КОМПЛЕКСНИЙ АНАЛІЗ НАВЧАЛЬНИХ ДОСЯГНЕНЬ З МЕТОДАМИ ОПТИМІЗАЦІЇ")
print("=" * 70)

# 1. ГЕНЕРАЦІЯ ДАНИХ З РІЗНИМИ ГРУПАМИ СТУДЕНТІВ
np.random.seed(42)
n_students = 300


def generate_realistic_student_data(n):
    # Створюємо різні групи студентів
    groups = {
        'excellent': {'prob': 0.15, 'ability_mean': 0.8, 'motivation_mean': 0.8},
        'good': {'prob': 0.35, 'ability_mean': 0.6, 'motivation_mean': 0.7},
        'satisfactory': {'prob': 0.35, 'ability_mean': 0.4, 'motivation_mean': 0.5},
        'weak': {'prob': 0.15, 'ability_mean': 0.2, 'motivation_mean': 0.3}
    }

    data = []
    group_labels = []

    for group_name, params in groups.items():
        n_group = int(n * params['prob'])

        for i in range(n_group):
            ability = np.random.normal(params['ability_mean'], 0.15)
            motivation = np.random.normal(params['motivation_mean'], 0.15)

            # Генерація залежних змінних
            study_hours = np.random.normal(15 + 10 * motivation, 4)
            attendance = np.random.normal(70 + 20 * motivation, 10)
            satisfaction = np.random.normal(6 + 2 * motivation, 1.5)
            add_courses = np.random.normal(8 + 6 * motivation, 3)

            # Реальна модель успішності з нелінійностями
            base_score = 30 + 30 * ability + 20 * motivation
            study_effect = 1.5 * study_hours - 0.025 * study_hours ** 2  # Спадна віддача
            attendance_effect = 0.4 * attendance
            satisfaction_effect = 2.0 * satisfaction
            courses_effect = 1.8 * add_courses

            exam_score = (
                    base_score +
                    study_effect +
                    attendance_effect +
                    satisfaction_effect +
                    courses_effect +
                    np.random.normal(0, 8)  # Реалістичний шум
            )

            # Обмеження значень (без штучного обмеження максимуму!)
            study_hours = max(4, min(35, study_hours))
            attendance = max(40, min(100, attendance))
            satisfaction = max(1, min(10, satisfaction))
            add_courses = max(0, min(25, add_courses))
            exam_score = max(20, exam_score)  # Тільки мінімальне обмеження

            data.append({
                'study_hours': round(study_hours, 1),
                'attendance_rate': round(attendance, 1),
                'satisfaction': round(satisfaction, 1),
                'add_courses': round(add_courses, 1),
                'exam_score': round(exam_score, 1),
                'motivation': round(motivation, 2),
                'ability': round(ability, 2)
            })
            group_labels.append(group_name)

    df = pd.DataFrame(data)
    df['group'] = group_labels
    return df


df = generate_realistic_student_data(n_students)

print("1. ОПИСОВА СТАТИСТИКА ДАНИХ")
print("=" * 40)
print(f"Розмірність датасету: {df.shape}")
print(f"\nРозподіл за групами:")
print(df['group'].value_counts())
print(f"\nОсновні статистики:")
print(df[['study_hours', 'attendance_rate', 'satisfaction', 'add_courses', 'exam_score']].describe())

# 2. ВІЗУАЛІЗАЦІЯ ДАНИХ
plt.figure(figsize=(15, 12))

# Матриця кореляцій
plt.subplot(2, 3, 1)
correlation_matrix = df[['study_hours', 'attendance_rate', 'exam_score', 'satisfaction', 'add_courses']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Матриця кореляцій навчальних показників')

# Розподіл балів
plt.subplot(2, 3, 2)
plt.hist(df['exam_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
plt.xlabel('Екзаменаційний бал')
plt.ylabel('Кількість студентів')
plt.title('Розподіл екзаменаційних балів')

# Залежність від годин навчання
plt.subplot(2, 3, 3)
colors = {'excellent': 'red', 'good': 'blue', 'satisfactory': 'green', 'weak': 'orange'}
for group in df['group'].unique():
    group_data = df[df['group'] == group]
    plt.scatter(group_data['study_hours'], group_data['exam_score'],
                alpha=0.6, color=colors[group], label=group)
plt.xlabel('Години навчання')
plt.ylabel('Екзаменаційний бал')
plt.title('Залежність балу від годин навчання')
plt.legend()

# Залежність від відвідуваності
plt.subplot(2, 3, 4)
for group in df['group'].unique():
    group_data = df[df['group'] == group]
    plt.scatter(group_data['attendance_rate'], group_data['exam_score'],
                alpha=0.6, color=colors[group], label=group)
plt.xlabel('Відвідуваність (%)')
plt.ylabel('Екзаменаційний бал')
plt.title('Залежність балу від відвідуваності')
plt.legend()

# Бали по групах
plt.subplot(2, 3, 5)
group_stats = df.groupby('group')['exam_score'].agg(['mean', 'std'])
plt.bar(group_stats.index, group_stats['mean'],
        yerr=group_stats['std'], capsize=5, alpha=0.7,
        color=[colors[group] for group in group_stats.index])
plt.ylabel('Середній бал')
plt.title('Середні бали за групами')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# 3. КОРЕЛЯЦІЙНИЙ АНАЛІЗ
print("\n\n2. КОРЕЛЯЦІЙНИЙ АНАЛІЗ")
print("=" * 40)

study_corr = stats.pearsonr(df['study_hours'], df['exam_score'])
attendance_corr = stats.pearsonr(df['attendance_rate'], df['exam_score'])
satisfaction_corr = stats.pearsonr(df['satisfaction'], df['exam_score'])
courses_corr = stats.pearsonr(df['add_courses'], df['exam_score'])

print(f"Кореляція години навчання - успішність: r = {study_corr[0]:.3f} (p = {study_corr[1]:.3f})")
print(f"Кореляція відвідуваність - успішність: r = {attendance_corr[0]:.3f} (p = {attendance_corr[1]:.3f})")
print(f"Кореляція задоволеність - успішність: r = {satisfaction_corr[0]:.3f} (p = {satisfaction_corr[1]:.3f})")
print(f"Кореляція дод. курси - успішність: r = {courses_corr[0]:.3f} (p = {courses_corr[1]:.3f})")

# 4. РЕГРЕСІЙНА МОДЕЛЬ
print("\n\n3. РЕГРЕСІЙНА МОДЕЛЬ ДЛЯ ОПТИМІЗАЦІЇ")
print("=" * 50)

X = df[['study_hours', 'attendance_rate', 'satisfaction', 'add_courses']]
y = df['exam_score']

# Масштабування
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Лінійна регресія
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)

print("РЕГРЕСІЙНЕ РІВНЯННЯ:")
equation = f"exam_score = {lr_model.intercept_:.2f}"
features = ['study_hours', 'attendance_rate', 'satisfaction', 'add_courses']
for i, feature in enumerate(features):
    coef = lr_model.coef_[i]
    sign = " + " if coef >= 0 else " - "
    equation += f"{sign}{abs(coef):.2f}×{feature}"
print(equation)
print(f"Якість моделі: R^2 = {r2:.4f}, MSE = {mse:.2f}")


# 5. ФУНКЦІЯ ДЛЯ ОПТИМІЗАЦІЇ
def student_score(x):

    x_scaled = scaler.transform([x])
    return -lr_model.predict(x_scaled)[0]  # Мінус для мінімізації


# Обмеження
bounds = [
    (10, 35),  # study_hours
    (50, 100),  # attendance_rate
    (4, 10),  # satisfaction
    (5, 20)  # add_courses
]

# Початкова точка
x0 = [20, 80, 7, 12]

print(f"\nПочаткова точка: {x0}")
print(f"Початковий бал: {-student_score(x0):.1f}")

# 6. ГРАДІЄНТНІ МЕТОДИ
print("\n\n4. ПОРІВНЯННЯ АЛГОРИТМІВ СПРЯЖЕНИХ ГРАДІЄНТІВ")
print("=" * 55)

gradient_methods = ['CG', 'BFGS', 'L-BFGS-B', 'SLSQP']
gradient_results = {}

for method in gradient_methods:
    try:
        start_time = time.time()
        result = minimize(student_score, x0, method=method, bounds=bounds,
                          options={'maxiter': 1000})
        end_time = time.time()

        if result.success:
            gradient_results[method] = {
                'x_opt': result.x,
                'f_opt': -result.fun,
                'time': end_time - start_time,
                'iterations': result.nit,
                'success': result.success
            }

            print(f"\n{method}:")
            print(f"  Оптимальний бал: {-result.fun:.1f}")
            print(
                f"  Параметри: години={result.x[0]:.1f}, відвідуваність={result.x[1]:.1f}%, задоволеність={result.x[2]:.1f}, курси={result.x[3]:.1f}")
            print(f"  Час: {end_time - start_time:.4f} сек, Ітерації: {result.nit}")
        else:
            print(f"\n{method}: Не вдалося знайти рішення - {result.message}")
    except Exception as e:
        print(f"\n{method}: Помилка - {e}")

# 7. ЕВОЛЮЦІЙНІ МЕТОДИ
print("\n\n5. ЕВОЛЮЦІЙНІ МЕТОДИ ОПТИМІЗАЦІЇ")
print("=" * 50)


def evolutionary_optimization(f_obj, bounds, pop_size=50, generations=100, mutation_rate=0.1):

    n_params = len(bounds)

    # Стратегія створення початкової популяції
    population = np.zeros((pop_size, n_params))
    for i in range(n_params):
        population[:, i] = np.random.uniform(bounds[i][0], bounds[i][1], pop_size)

    best_fitness = []

    for gen in range(generations):
        # Оцінка пристосованості
        fitness = np.array([-f_obj(ind) for ind in population])

        # Відбір (турнірний)
        new_population = []
        for _ in range(pop_size):
            idx1, idx2 = np.random.choice(pop_size, 2, replace=False)
            if fitness[idx1] > fitness[idx2]:
                new_population.append(population[idx1].copy())
            else:
                new_population.append(population[idx2].copy())

        population = np.array(new_population)

        # Кросовер (одноточковий)
        for i in range(0, pop_size - 1, 2):
            if np.random.random() < 0.8:
                cross_point = np.random.randint(1, n_params)
                temp = population[i, cross_point:].copy()
                population[i, cross_point:] = population[i + 1, cross_point:]
                population[i + 1, cross_point:] = temp

        # Мутація
        for i in range(pop_size):
            for j in range(n_params):
                if np.random.random() < mutation_rate:
                    population[i, j] += np.random.normal(0, (bounds[j][1] - bounds[j][0]) * 0.1)
                    population[i, j] = np.clip(population[i, j], bounds[j][0], bounds[j][1])

        best_fitness.append(np.max(fitness))

    # Найкраща особина
    best_idx = np.argmax([-f_obj(ind) for ind in population])
    return population[best_idx], best_fitness


print("\nЗапуск еволюційного алгоритму...")
start_time = time.time()
x_opt_ea, fitness_history = evolutionary_optimization(student_score, bounds)
end_time = time.time()

print(f"Еволюційний алгоритм:")
print(f"  Оптимальний бал: {-student_score(x_opt_ea):.1f}")
print(
    f"  Параметри: години={x_opt_ea[0]:.1f}, відвідуваність={x_opt_ea[1]:.1f}%, задоволеність={x_opt_ea[2]:.1f}, курси={x_opt_ea[3]:.1f}")
print(f"  Час: {end_time - start_time:.4f} сек")

# 8. МЕТОД МУРАШИНИХ КОЛОНІЙ
print("\n\n6. МЕТОД МУРАШИНИХ КОЛОНІЙ")
print("=" * 40)


def ant_colony_optimization(f_obj, bounds, n_ants=30, n_iterations=100, evaporation=0.5):

    n_params = len(bounds)

    best_solution = None
    best_fitness = -np.inf
    fitness_history = []

    for iteration in range(n_iterations):
        solutions = []
        fitnesses = []

        for ant in range(n_ants):
            # Генерація випадкового рішення
            solution = np.zeros(n_params)
            for i in range(n_params):
                solution[i] = np.random.uniform(bounds[i][0], bounds[i][1])

            fitness = -f_obj(solution)
            solutions.append(solution)
            fitnesses.append(fitness)

            if fitness > best_fitness:
                best_fitness = fitness
                best_solution = solution.copy()

        fitness_history.append(best_fitness)

    return best_solution, best_fitness, fitness_history


print("\nЗапуск методу мурашиних колоній...")
start_time = time.time()
x_opt_aco, best_fitness_aco, aco_fitness_history = ant_colony_optimization(student_score, bounds)
end_time = time.time()

print(f"Метод мурашиних колоній:")
print(f"  Оптимальний бал: {best_fitness_aco:.1f}")
print(
    f"  Параметри: години={x_opt_aco[0]:.1f}, відвідуваність={x_opt_aco[1]:.1f}%, задоволеність={x_opt_aco[2]:.1f}, курси={x_opt_aco[3]:.1f}")
print(f"  Час: {end_time - start_time:.4f} сек")

# 9. ПОРІВНЯЛЬНИЙ АНАЛІЗ
print("\n\n7. ПОРІВНЯЛЬНИЙ АНАЛІЗ МЕТОДІВ ОПТИМІЗАЦІЇ")
print("=" * 55)

comparison_data = []

# Додаємо результати градієнтних методів
for method, res in gradient_results.items():
    comparison_data.append({
        'Method': method,
        'Score': res['f_opt'],
        'Time (s)': res['time'],
        'Iterations': res['iterations'],
        'Type': 'Градієнтний'
    })

# Додаємо еволюційний метод
comparison_data.append({
    'Method': 'Evolutionary',
    'Score': -student_score(x_opt_ea),
    'Time (s)': end_time - start_time,
    'Iterations': 100,
    'Type': 'Еволюційний'
})

# Додаємо метод мурашиних колоній
comparison_data.append({
    'Method': 'Ant Colony',
    'Score': best_fitness_aco,
    'Time (s)': end_time - start_time,
    'Iterations': 100,
    'Type': 'Роєвий інтелект'
})

comparison_df = pd.DataFrame(comparison_data)
print("\nПорівняльна таблиця методів:")
print(comparison_df.to_string(index=False, float_format='%.3f'))

# 10. ВІЗУАЛІЗАЦІЯ РЕЗУЛЬТАТІВ
plt.figure(figsize=(15, 10))

# Порівняння методів
plt.subplot(2, 2, 1)
methods = comparison_df['Method']
scores = comparison_df['Score']
colors = ['blue', 'green', 'red', 'orange', 'purple']

bars = plt.bar(methods, scores, color=colors[:len(methods)])
plt.ylabel('Оптимальний бал')
plt.title('Порівняння оптимальних балів')
plt.xticks(rotation=45)
for bar, score in zip(bars, scores):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1, f'{score:.1f}',
             ha='center', va='bottom', fontsize=10)
plt.grid(True, alpha=0.3)

# Збіжність еволюційного алгоритму
plt.subplot(2, 2, 2)
plt.plot(fitness_history)
plt.title('Збіжність еволюційного алгоритму')
plt.xlabel('Покоління')
plt.ylabel('Найкращий бал')
plt.grid(True, alpha=0.3)

# Кластеризація
plt.subplot(2, 2, 3)
X_cluster = df[['study_hours', 'attendance_rate', 'exam_score']]
kmeans = KMeans(n_clusters=4, random_state=42)
df['cluster'] = kmeans.fit_predict(X_cluster)

scatter = plt.scatter(df['study_hours'], df['exam_score'], c=df['cluster'], cmap='viridis', alpha=0.7)
plt.xlabel('Години навчання')
plt.ylabel('Екзаменаційний бал')
plt.title('Кластеризація студентів')
plt.colorbar(scatter)
plt.grid(True, alpha=0.3)

# Важливість ознак
plt.subplot(2, 2, 4)
tree_model = DecisionTreeRegressor(max_depth=3, random_state=42)
tree_model.fit(X_train, y_train)
importance = tree_model.feature_importances_
plt.barh(features, importance)
plt.xlabel('Важливість ознаки')
plt.title('Важливість факторів успішності')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 11. ВИСНОВКИ
print("\n\n8. ВИСНОВКИ ТА РЕКОМЕНДАЦІЇ")
print("=" * 45)

print(f"""
РЕАЛІСТИЧНІ РЕЗУЛЬТАТИ:

1. ДАНІ ТА МОДЕЛЬ:
- Середній бал: {df['exam_score'].mean():.1f} ± {df['exam_score'].std():.1f}
- Діапазон балів: {df['exam_score'].min():.1f} - {df['exam_score'].max():.1f}
- Якість моделі: R^2 = {r2:.4f}

2. КОРЕЛЯЦІЇ:
- Найсильніша кореляція: {features[np.argmax([abs(study_corr[0]), abs(attendance_corr[0]), abs(satisfaction_corr[0]), abs(courses_corr[0])])]} 
  (r = {max(abs(study_corr[0]), abs(attendance_corr[0]), abs(satisfaction_corr[0]), abs(courses_corr[0])):.3f})

3. МЕТОДИ ОПТИМІЗАЦІЇ:
- Найкращий результат: {comparison_df.loc[comparison_df['Score'].idxmax(), 'Method']} 
  ({comparison_df['Score'].max():.1f} балів)
- Найшвидший метод: {comparison_df.loc[comparison_df['Time (s)'].idxmin(), 'Method']}
  ({comparison_df['Time (s)'].min():.3f} сек)

4. ОПТИМАЛЬНІ ПАРАМЕТРИ:
- Години навчання: {x_opt_ea[0]:.1f}
- Відвідуваність: {x_opt_ea[1]:.1f}%
- Задоволеність: {x_opt_ea[2]:.1f}
- Додаткові курси: {x_opt_ea[3]:.1f}
""")

print("\n" + "=" * 70)
print("АНАЛІЗ УСПІШНОСТІ ЗАВЕРШЕНО!")
print("=" * 70)
